{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df099ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pyautogui\n",
    "from time import time\n",
    "from math import hypot\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c7140",
   "metadata": {},
   "source": [
    "## MediaPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab1ebcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize mediapipe pose class\n",
    "mp_pose=mp.solutions.pose\n",
    "\n",
    "#Setup the pose function for images\n",
    "pose_image=mp_pose.Pose(static_image_mode=True,min_detection_confidence=0.5,model_complexity=1)\n",
    "\n",
    "#Setup the pose function for videos\n",
    "pose_video=mp_pose.Pose(static_image_mode=False,model_complexity=1,min_detection_confidence=0.7,min_tracking_confidence=0.7)\n",
    "\n",
    "#Initialize mediapipe drawing class\n",
    "mp_drawing=mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85ecd4",
   "metadata": {},
   "source": [
    "## Metodlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a221418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectPose(image,pose,draw=False,display=False):\n",
    "    \n",
    "    #create a copy of the input image\n",
    "    output_image=image.copy()\n",
    "    \n",
    "    #Convert the image from BGR to RGB format\n",
    "    imageRGB=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #perform the Pose detection\n",
    "    results=pose.process(imageRGB)\n",
    "    \n",
    "    #Check if any landmarks are detected and are specified to be drawn\n",
    "    if results.pose_landmarks and draw:\n",
    "        #Draw pose landmarks on the output image\n",
    "        mp_drawing.draw_landmarks(image=output_image,landmark_list=results.pose_landmarks,\n",
    "                                 connections=mp_pose.POSE_CONNECTIONS,\n",
    "                                  landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255,255,255),\n",
    "                                                                              thickness=3,circle_radius=3),\n",
    "                                 connection_drawing_spec=mp_drawing.DrawingSpec(color=(49,125,237),\n",
    "                                                                               thickness=2,circle_radius=2))\n",
    "    \n",
    "    #Check if the original input image and the resultant image are specified to be displayed\n",
    "    if display:\n",
    "        \n",
    "        #Display the original input image and the resultant image\n",
    "        plt.figure(figsize=[22,22])\n",
    "        plt.subplot(121);\n",
    "        plt.imshow(image[:,:,::-1]);plt.title(\"Original Image\");plt.axis(\"off\");\n",
    "        plt.subplot(122);\n",
    "        plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis(\"off\");\n",
    "        \n",
    "    else:\n",
    "        #Return the output image and the results of pose landmarks detection\n",
    "        return output_image,results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15f2a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkHandsJoined(image,results,draw=False,display=False):\n",
    "    #Get the height and width of the input image\n",
    "    height,width,_=image.shape\n",
    "    \n",
    "    #Create a copy of the input image to write the hands status label on\n",
    "    output_image=image.copy()\n",
    "    \n",
    "    #Get the left wrist landmark x and y coordinates\n",
    "    left_wrist_landmark=(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST].x*width,\n",
    "                        results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST].y*height)\n",
    "    \n",
    "    #Get the right wrist landmark x and y coordinates\n",
    "    right_wrist_landmark=(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST].x*width,\n",
    "                        results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST].y*height)\n",
    "    \n",
    "    #Calculate the euclidean distance between the left and right wrist\n",
    "    euclidean_distance=int(hypot(left_wrist_landmark[0]-right_wrist_landmark[0],\n",
    "                                left_wrist_landmark[1]-right_wrist_landmark[1]))\n",
    "    #Compare the distance between the wrists with a appropriate threshold to check if both hands are joined\n",
    "    if euclidean_distance<130:\n",
    "        #Set the hands status to joined\n",
    "        hand_status=\"Eller Birlesti\"\n",
    "        \n",
    "        # Set the color value to green\n",
    "        color=(0,255,0)\n",
    "    else:\n",
    "        #Set the hands status to not joined\n",
    "        hand_status=\"Eller Birlestirilmedi\"\n",
    "        color=(0,255,0)\n",
    "        \n",
    "    #Check if the hands joined status and hands are specified to be written on the output image\n",
    "    if draw:\n",
    "        \n",
    "        #Write the classified hands status on the image\n",
    "        cv2.putText(output_image,hand_status,(10,30),cv2.FONT_HERSHEY_PLAIN,2,color,3)\n",
    "        \n",
    "        #Write the distance between the wrists on the image\n",
    "        cv2.putText(output_image,f'Distance: {euclidean_distance}',(10,70),cv2.FONT_HERSHEY_PLAIN,2,color,3)\n",
    "        \n",
    "    #Check if the output image is specified to be displayed\n",
    "    if display:\n",
    "        #Display the output image\n",
    "        plt.figure(figsize=[10,10])\n",
    "        plt.imshow(output_image[:,:,::,-1]);\n",
    "        plt.title(\"Output Image\");plt.axis('off');\n",
    "    else:\n",
    "        \n",
    "        #Return the output image and the classified hands status indicating whether the hands are joined or not\n",
    "        return output_image,hand_status\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6cc9877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkLeftRight(image,results,draw=False,display=False):\n",
    "    \n",
    "     #Declare a variable to store the horizontal position(left, center, right) of the person\n",
    "    horizontal_position=None\n",
    "    \n",
    "     #Get the height and width of the image\n",
    "    height,width,_=image.shape\n",
    "    \n",
    "     #Create a copy of the input image to write the horizontal position on\n",
    "    output_image=image.copy()\n",
    "    \n",
    "     #Retrieve the x-coordinate of the left shoulder landmark\n",
    "    left_x=int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x*width)\n",
    "    \n",
    "     #Retrieve the y-coordinate of the right shoulder landmark\n",
    "    right_x=int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x*width)\n",
    "    \n",
    "     #Check if the person is at left that is when both shoulder landmarks x-coordinates are less than or equal to the\n",
    "     # x-coordinate of the center of the image\n",
    "    if (right_x<=width//2 and left_x<=width//2):\n",
    "        \n",
    "         #Set the person's position to left\n",
    "        horizontal_position='Sol'\n",
    "        \n",
    "     #Check if the person is at right that is when both shoulder landmarks x-coordinates are greater than or equal to the\n",
    "     # x-coordinate of the center of the image\n",
    "    elif(right_x>=width//2 and left_x>=width//2):\n",
    "        \n",
    "         #Set the person's position to right\n",
    "        horizontal_position='Sag'\n",
    "        \n",
    "            \n",
    "     #Check if the person is at center that is when right shoulder landmarks x-coordinates are greater than or equal \n",
    "     #to and the left shoulder landmarks x-coordinates are less than or equal to the\n",
    "     # x-coordinate of the center of the image\n",
    "    \n",
    "    #elif(right_x>=width//2 and left_x<=width//2):\n",
    "        \n",
    "         #Set the person's position to right\n",
    "     #   horizontal_position='Center'\n",
    "    \n",
    "     # Check if the person's horizontal position and a line at the center of the image is specified to be drawn\n",
    "    if draw:\n",
    "        \n",
    "         #Write the horizontal position of the person on the image\n",
    "        cv2.putText(output_image,horizontal_position,(5,height-250),cv2.FONT_HERSHEY_PLAIN,2,(0,0,0),2)\n",
    "        \n",
    "         #Draw a line at the center of the image\n",
    "        cv2.line(output_image,(width//2,0),(width//2,height),(0,255,0),1)\n",
    "        \n",
    "     #Check if the output image is specified to be displayed\n",
    "    if display:\n",
    "        \n",
    "         #Display the output image\n",
    "        plt.figure(figsize=[10,10])\n",
    "        plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis(\"off\");\n",
    "    else:\n",
    "       \n",
    "         #Return the output image and the person's horizontal position\n",
    "        return output_image,horizontal_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "592b43a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkJumpCrouch(image, results, MID_Y=250, draw=False, display=False):\n",
    "    \n",
    "     # Get the height and width of the image.\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "     # Create a copy of the input image to write the posture label on.\n",
    "    output_image = image.copy()\n",
    "    \n",
    "     # Retreive the y-coordinate of the left shoulder landmark.\n",
    "    left_y = int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * height)\n",
    " \n",
    "     # Retreive the y-coordinate of the right shoulder landmark.\n",
    "    right_y = int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * height)\n",
    " \n",
    "     # Calculate the y-coordinate of the mid-point of both shoulders.\n",
    "    actual_mid_y = abs(right_y + left_y) // 2\n",
    "    \n",
    "     # Calculate the upper and lower bounds of the threshold.\n",
    "    lower_bound = MID_Y-15\n",
    "    upper_bound = MID_Y+100\n",
    "    \n",
    "     # Check if the person has jumped that is when the y-coordinate of the mid-point \n",
    "     # of both shoulders is less than the lower bound.\n",
    "    if (actual_mid_y < lower_bound):\n",
    "        \n",
    "         # Set the posture to jumping.\n",
    "        posture = 'Jumping'\n",
    "    \n",
    "     # Check if the person has crouched that is when the y-coordinate of the mid-point \n",
    "     # of both shoulders is greater than the upper bound.\n",
    "    elif (actual_mid_y > upper_bound):\n",
    "        \n",
    "         # Set the posture to crouching.\n",
    "        posture = 'Crouching'\n",
    "    \n",
    "     # Otherwise the person is standing and the y-coordinate of the mid-point \n",
    "     # of both shoulders is between the upper and lower bounds.    \n",
    "    else:\n",
    "        \n",
    "         # Set the posture to Standing straight.\n",
    "        posture = 'Standing'\n",
    "        \n",
    "     # Check if the posture and a horizontal line at the threshold is specified to be drawn.\n",
    "    if draw:\n",
    " \n",
    "         # Write the posture of the person on the image. \n",
    "        cv2.putText(output_image, posture, (5, height - 50), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 3)\n",
    "        \n",
    "         # Draw a line at the intial center y-coordinate of the person (threshold).\n",
    "        cv2.line(output_image, (0, MID_Y),(width, MID_Y),(255, 255, 255), 2)\n",
    "        \n",
    "     # Check if the output image is specified to be displayed.\n",
    "    if display:\n",
    " \n",
    "         # Display the output image.\n",
    "        plt.figure(figsize=[10,10])\n",
    "        plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "    \n",
    "     # Otherwise\n",
    "    else:\n",
    "    \n",
    "         # Return the output image and posture indicating whether the person is standing straight or has jumped, or crouched.\n",
    "        return output_image, posture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bbc52e",
   "metadata": {},
   "source": [
    "## Yukarıdakiler bir kere çalışması yeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a64d7d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_video = cv2.VideoCapture(0)\n",
    "#camera_video.set(3,1280)\n",
    "#camera_video.set(4,960)\n",
    " \n",
    "# Create named window for resizing purposes.\n",
    "cv2.namedWindow('Pose Detection', cv2.WINDOW_NORMAL)\n",
    " \n",
    "# Initialize a variable to store the time of the previous frame.\n",
    "time1 = 0\n",
    " \n",
    "# Initialize a variable to store the state of the game (started or not).\n",
    "game_started = False   \n",
    " \n",
    "# Initialize a variable to store the index of the current horizontal position of the person.\n",
    "# At Start the character is at center so the index is 1 and it can move left (value 0) and right (value 2).\n",
    "x_pos_index = 1\n",
    " \n",
    "# Initialize a variable to store the index of the current vertical posture of the person.\n",
    "# At Start the person is standing so the index is 1 and he can crouch (value 0) and jump (value 2).\n",
    "y_pos_index = 1\n",
    " \n",
    "# Declate a variable to store the intial y-coordinate of the mid-point of both shoulders of the person.\n",
    "MID_Y = None\n",
    " \n",
    "# Initialize a counter to store count of the number of consecutive frames with person's hands joined.\n",
    "counter = 0\n",
    " \n",
    "# Initialize the number of consecutive frames on which we want to check if person hands joined before starting the game.\n",
    "num_of_frames = 20\n",
    " \n",
    "# Iterate until the webcam is accessed successfully.\n",
    "while camera_video.isOpened():\n",
    "    \n",
    "    # Read a frame.\n",
    "    ok, frame = camera_video.read()\n",
    "    \n",
    "    # Check if frame is not read properly then continue to the next iteration to read the next frame.\n",
    "    if not ok:\n",
    "        continue\n",
    "    \n",
    "    # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Get the height and width of the frame of the webcam video.\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    \n",
    "    # Perform the pose detection on the frame.\n",
    "    frame, results = detectPose(frame, pose_video, draw=game_started)\n",
    "    \n",
    "    # Check if the pose landmarks in the frame are detected.\n",
    "    if results.pose_landmarks:\n",
    "        #frame,_=checkHandsJoined(frame,results,draw=True)\n",
    "        \n",
    "        # Check if the game has started\n",
    "        if game_started:\n",
    "            \n",
    "            # Commands to control the horizontal movements of the character.\n",
    "            #--------------------------------------------------------------------------------------------------------------\n",
    "            \n",
    "            # Get horizontal position of the person in the frame.\n",
    "            frame, horizontal_position = checkLeftRight(frame, results, draw=True)\n",
    "            \n",
    "            \n",
    "            # Check if the person has moved to left from center or to center from right.\n",
    "            if (horizontal_position=='Sol' and x_pos_index!=0): #or (horizontal_position=='Center' and x_pos_index==2):\n",
    "                \n",
    "                # Press the left arrow key.\n",
    "                pyautogui.press('left')\n",
    "                \n",
    "                # Update the horizontal position index of the character.\n",
    "                x_pos_index -= 1               \n",
    " \n",
    "            # Check if the person has moved to Right from center or to center from left.\n",
    "            elif (horizontal_position=='Sag' and x_pos_index!=2): #or (horizontal_position=='Center' and x_pos_index==0):\n",
    "                \n",
    "                # Press the right arrow key.\n",
    "                pyautogui.press('right')\n",
    "                \n",
    "                # Update the horizontal position index of the character.\n",
    "                x_pos_index += 1\n",
    "            \n",
    "            \n",
    "            #--------------------------------------------------------------------------------------------------------------\n",
    "            \n",
    "            # Command to start the game again after death of the character\n",
    "            #-------------------------------------------------------------\n",
    "            \n",
    "            if checkHandsJoined(frame,results)[1]=='Eller Birlestirildi':\n",
    "                pyautogui.press('g')\n",
    "                \n",
    "        # Otherwise if the game has not started    \n",
    "        else:\n",
    "            \n",
    "            # Command to Start the game first time\n",
    "            #------------------------------------------------------------------------------------------------------------------\n",
    "            \n",
    "            # Write the text representing the way to start the game on the frame. \n",
    "            cv2.putText(frame, 'Baslamak icin ellerini birlestir', (5, frame_height - 10), cv2.FONT_HERSHEY_PLAIN,\n",
    "                        2, (0, 255, 0), 3)\n",
    "        \n",
    "        # Check if the left and right hands are joined.\n",
    "            if checkHandsJoined(frame, results)[1] == 'Eller Birlesti':\n",
    "                \n",
    "                # Increment the count of consecutive frames with +ve condition.\n",
    "                counter += 1\n",
    " \n",
    "                # Check if the counter is equal to the required number of consecutive frames.  \n",
    "                if counter == num_of_frames:\n",
    "\n",
    "                        # Update the value of the variable that stores the game state.\n",
    "                        game_started = True\n",
    "                        pyautogui.press('g')\n",
    "                        # Retreive the y-coordinate of the left shoulder landmark.\n",
    "                        left_y = int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * frame_height)\n",
    "\n",
    "                        # Retreive the y-coordinate of the right shoulder landmark.\n",
    "                        right_y = int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * frame_height)\n",
    "\n",
    "                        # Calculate the intial y-coordinate of the mid-point of both shoulders of the person.\n",
    "                        MID_Y = abs(right_y + left_y) // 2\n",
    "\n",
    "                        # Move to 1300, 800, then click the left mouse button to start the game.\n",
    "                        #pyautogui.click(x=1300, y=800, button='left')\n",
    " \n",
    "            # Otherwise if the left and right hands are not joined.        \n",
    "            else:\n",
    "\n",
    "                # Update the counter value to zero.\n",
    "                counter = 0\n",
    "            \n",
    "        #------------------------------------------------------------------------------------------------------------------\n",
    " \n",
    "        # Commands to control the vertical movements of the character.\n",
    "        #------------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Check if the intial y-coordinate of the mid-point of both shoulders of the person has a value.\n",
    "        if MID_Y:\n",
    "            \n",
    "            # Get posture (jumping, crouching or standing) of the person in the frame. \n",
    "            frame, posture = checkJumpCrouch(frame, results, MID_Y, draw=True)\n",
    "            \n",
    "            # Check if the person has jumped.\n",
    "            if posture == 'Jumping' and y_pos_index == 1:\n",
    " \n",
    "                # Press the up arrow key\n",
    "                pyautogui.press('space')\n",
    "                \n",
    "                # Update the veritcal position index of  the character.\n",
    "                y_pos_index += 1 \n",
    " \n",
    "            # Check if the person has crouched.\n",
    "            elif posture == 'Crouching' and y_pos_index == 1:\n",
    " \n",
    "                # Press the down arrow key\n",
    "                pyautogui.press('down')\n",
    "                \n",
    "                # Update the veritcal position index of the character.\n",
    "                y_pos_index -= 1\n",
    "            \n",
    "            # Check if the person has stood.\n",
    "            elif posture == 'Standing' and y_pos_index   != 1:\n",
    "                \n",
    "                # Update the veritcal position index of the character.\n",
    "                y_pos_index = 1\n",
    "        \n",
    "        #------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    # Otherwise if the pose landmarks in the frame are not detected.       \n",
    "    else:\n",
    "#############################\n",
    "        #cv2.imshow(\"Insan Surati Tespit Edilemedi!!!\",frame)\n",
    "#############################\n",
    "        # Update the counter value to zero.\n",
    "        counter = 0\n",
    "        \n",
    "    # Calculate the frames updates in one second\n",
    "    #----------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Set the time for this frame to the current time.\n",
    "    time2 = time()\n",
    "    \n",
    "    # Check if the difference between the previous and this frame time &gt; 0 to avoid division by zero.\n",
    "    if (time2 - time1) > 0:\n",
    "    \n",
    "        # Calculate the number of frames per second.\n",
    "        frames_per_second = 1.0 / (time2 - time1)\n",
    "        \n",
    "        # Write the calculated number of frames per second on the frame. \n",
    "        cv2.putText(frame, 'FPS: {}'.format(int(frames_per_second)), (10, 30),cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 3)\n",
    "    \n",
    "    # Update the previous frame time to this frame time.\n",
    "    # As this frame will become previous frame in next iteration.\n",
    "    time1 = time2\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Display the frame.            \n",
    "    cv2.imshow('Pose Detection', frame)\n",
    "    \n",
    "    # Wait for 1ms. If a a key is pressed, retreive the ASCII code of the key.\n",
    "    k = cv2.waitKey(1) &0xFF    \n",
    "    \n",
    "    # Check if 'ESC' is pressed and break the loop.\n",
    "    if(k == 27):\n",
    "        break\n",
    " \n",
    "\n",
    " # Release the VideoCapture Object and close the windows.                  \n",
    "camera_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ff84a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df62851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef9d56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
